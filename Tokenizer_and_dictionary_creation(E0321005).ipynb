{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0oZWDWpMWj3i"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1CzTOEFWngW",
        "outputId": "4da71cce-6618-4809-eadb-a2ec854f0538"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = \"Dragons don't exist they said. They are the stuff of legend and people's imagination. Greg would have agreed with this assessment without a second thought 24 hours ago. But now that there was a dragon staring directly into his eyes, he questioned everything that he had been told.\""
      ],
      "metadata": {
        "id": "IvIQejrzWzPk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = p.split(\".\")"
      ],
      "metadata": {
        "id": "qy9FMcR4XE5I"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [sentence.strip().split() for sentence in s if sentence.strip()]"
      ],
      "metadata": {
        "id": "fVhlui9GXLBS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in tokenized_sentences:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wgr2qOsXXuU",
        "outputId": "59d34ce5-8cd6-4da7-d0a5-0c5486bd6953"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', \"don't\", 'exist', 'they', 'said']\n",
            "['They', 'are', 'the', 'stuff', 'of', 'legend', 'and', \"people's\", 'imagination']\n",
            "['Greg', 'would', 'have', 'agreed', 'with', 'this', 'assessment', 'without', 'a', 'second', 'thought', '24', 'hours', 'ago']\n",
            "['But', 'now', 'that', 'there', 'was', 'a', 'dragon', 'staring', 'directly', 'into', 'his', 'eyes,', 'he', 'questioned', 'everything', 'that', 'he', 'had', 'been', 'told']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set([word for sentence in tokenized_sentences for word in sentence])\n",
        "print(\"Vocabulary:\",vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69calTp_Xl27",
        "outputId": "0b7ee680-7a84-4b5c-d7fa-91ea859eb9a1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'exist', 'Greg', 'the', 'that', 'legend', 'been', \"don't\", 'without', 'would', 'questioned', 'they', 'a', 'of', 'eyes,', 'there', 'imagination', 'stuff', 'directly', 'have', 'assessment', 'dragon', 'this', 'second', 'Dragons', 'was', 'ago', 'he', \"people's\", 'into', 'his', 'now', 'everything', 'and', 'agreed', 'are', 'hours', 'They', 'thought', 'staring', 'told', 'with', 'But', '24', 'had', 'said'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1 =  \"I don't like bananas They're always late This was co-created by my friend This document was signed 12-02-24\""
      ],
      "metadata": {
        "id": "8hWME1zlYuTT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2 = p1.split(\".\")"
      ],
      "metadata": {
        "id": "JQe4pkeraUbU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_sentence = [sentence.strip().split() for sentence in s2 if sentence.strip()]"
      ],
      "metadata": {
        "id": "gY4u0EXlaeQU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in tokenize_sentence:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmiOli9Ha0q7",
        "outputId": "7f3ad3cc-7c30-4f27-c8f9-2fe1b5065f46"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', \"don't\", 'like', 'bananas', \"They're\", 'always', 'late', 'This', 'was', 'co-created', 'by', 'my', 'friend', 'This', 'document', 'was', 'signed', '12-02-24']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary1 = set([word for sentence in tokenize_sentence for word in sentence])\n",
        "print(\"Vocabulary:\",vocabulary1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAF3KTldb3Vn",
        "outputId": "677ba14d-7534-445b-b35c-89026bc2445f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'my', 'like', 'by', 'late', \"don't\", \"They're\", 'co-created', 'always', 'signed', 'was', '12-02-24', 'bananas', 'I', 'document', 'friend', 'This'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aaViSawHa7L6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}